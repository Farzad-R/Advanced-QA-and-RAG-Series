{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Tools and Configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_notebook_config import LoadConfig\n",
    "from tools.tools_lookup_policy import lookup_policy\n",
    "from tools.tools_flights import fetch_user_flight_information, search_flights, update_ticket_to_new_flight, cancel_ticket\n",
    "from tools.tools_hotels import search_hotels, book_hotel, update_hotel, cancel_hotel\n",
    "from tools.tools_excursions import search_trip_recommendations, book_excursion, update_excursion, cancel_excursion\n",
    "from tools.tools_car_rental import search_car_rentals, book_car_rental, update_car_rental, cancel_car_rental\n",
    "from utils.utilities import create_tool_node_with_fallback, _print_event\n",
    "\n",
    "CFG = LoadConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defing the State**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to track which sub-graph is in control at any given time. While itâ€™s possible to infer this through arithmetic on the message list, maintaining a dedicated stack simplifies the process.\n",
    "\n",
    "Add a `dialog_state` list to the `State` below. Whenever a `node` runs and provides a value for `dialog_state`, the `update_dialog_stack` function will be invoked to decide how to apply the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"update_flight\",\n",
    "                \"book_car_rental\",\n",
    "                \"book_hotel\",\n",
    "                \"book_excursion\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the Assistant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistants\n",
    "\n",
    "This time we will create an assistant for every workflow. That means:\n",
    "\n",
    "1. Flight booking assistant\n",
    "2. Hotel booking assistant\n",
    "3. Car rental assistant\n",
    "4. Excursion assistant\n",
    "5. and finally, a \"primary assistant\" to route between these\n",
    "If you're paying attention, you may recognize this as an example of the supervisor design pattern from our Multi-agent examples.\n",
    "\n",
    "Below, define the `Runnable` objects to power each assistant. Each Runnable has a prompt, LLM, and schemas for the tools scoped to that assistant. Each specialized / delegated assistant additionally can call the `CompleteOrEscalate` tool to indicate that the control flow should be passed back to the primary assistant. This happens if it has successfully completed its work or if the user has changed their mind or needs assistance on something that beyond the scope of that particular workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "\n",
    "    cancel: bool = True\n",
    "    reason: str\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"User changed their mind about the current task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 3\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to search the user's emails or calendar for more information.\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "# Flight booking assistant\n",
    "\n",
    "flight_booking_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling flight updates. \"\n",
    "            \" The primary assistant delegates work to you whenever the user needs help updating their bookings. \"\n",
    "            \"Confirm the updated flight details with the customer and inform them of any additional fees. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\n\\nCurrent user flight information:\\n<Flights>\\n{user_info}\\n</Flights>\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            \"\\n\\nIf the user needs help, and none of your tools are appropriate for it, then\"\n",
    "            ' \"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.',\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "update_flight_safe_tools = [search_flights]\n",
    "update_flight_sensitive_tools = [update_ticket_to_new_flight, cancel_ticket]\n",
    "update_flight_tools = update_flight_safe_tools + update_flight_sensitive_tools\n",
    "update_flight_runnable = flight_booking_prompt | llm.bind_tools(\n",
    "    update_flight_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Hotel Booking Assistant\n",
    "book_hotel_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling hotel bookings. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help booking a hotel. \"\n",
    "            \"Search for available hotels based on the user's preferences and confirm the booking details with the customer. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            '\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"CompleteOrEscalate\" the dialog to the host assistant.'\n",
    "            \" Do not waste the user's time. Do not make up invalid tools or functions.\"\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'what's the weather like this time of year?'\\n\"\n",
    "            \" - 'nevermind i think I'll book separately'\\n\"\n",
    "            \" - 'i need to figure out transportation while i'm there'\\n\"\n",
    "            \" - 'Oh wait i haven't booked my flight yet i'll do that first'\\n\"\n",
    "            \" - 'Hotel booking confirmed'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "book_hotel_safe_tools = [search_hotels]\n",
    "book_hotel_sensitive_tools = [book_hotel, update_hotel, cancel_hotel]\n",
    "book_hotel_tools = book_hotel_safe_tools + book_hotel_sensitive_tools\n",
    "book_hotel_runnable = book_hotel_prompt | llm.bind_tools(\n",
    "    book_hotel_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Car Rental Assistant\n",
    "book_car_rental_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling car rental bookings. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help booking a car rental. \"\n",
    "            \"Search for available car rentals based on the user's preferences and confirm the booking details with the customer. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            \"\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"\n",
    "            '\"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'what's the weather like this time of year?'\\n\"\n",
    "            \" - 'What flights are available?'\\n\"\n",
    "            \" - 'nevermind i think I'll book separately'\\n\"\n",
    "            \" - 'Oh wait i haven't booked my flight yet i'll do that first'\\n\"\n",
    "            \" - 'Car rental booking confirmed'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "book_car_rental_safe_tools = [search_car_rentals]\n",
    "book_car_rental_sensitive_tools = [\n",
    "    book_car_rental,\n",
    "    update_car_rental,\n",
    "    cancel_car_rental,\n",
    "]\n",
    "book_car_rental_tools = book_car_rental_safe_tools + book_car_rental_sensitive_tools\n",
    "book_car_rental_runnable = book_car_rental_prompt | llm.bind_tools(\n",
    "    book_car_rental_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Excursion Assistant\n",
    "\n",
    "book_excursion_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling trip recommendations. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help booking a recommended trip. \"\n",
    "            \"Search for available trip recommendations based on the user's preferences and confirm the booking details with the customer. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            '\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'nevermind i think I'll book separately'\\n\"\n",
    "            \" - 'i need to figure out transportation while i'm there'\\n\"\n",
    "            \" - 'Oh wait i haven't booked my flight yet i'll do that first'\\n\"\n",
    "            \" - 'Excursion booking confirmed!'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "book_excursion_safe_tools = [search_trip_recommendations]\n",
    "book_excursion_sensitive_tools = [book_excursion, update_excursion, cancel_excursion]\n",
    "book_excursion_tools = book_excursion_safe_tools + book_excursion_sensitive_tools\n",
    "book_excursion_runnable = book_excursion_prompt | llm.bind_tools(\n",
    "    book_excursion_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "\n",
    "# Primary Assistant\n",
    "class ToFlightBookingAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle flight updates and cancellations.\"\"\"\n",
    "\n",
    "    request: str = Field(\n",
    "        description=\"Any necessary followup questions the update flight assistant should clarify before proceeding.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ToBookCarRental(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle car rental bookings.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants to rent a car.\"\n",
    "    )\n",
    "    start_date: str = Field(description=\"The start date of the car rental.\")\n",
    "    end_date: str = Field(description=\"The end date of the car rental.\")\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the car rental.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"location\": \"Basel\",\n",
    "                \"start_date\": \"2023-07-01\",\n",
    "                \"end_date\": \"2023-07-05\",\n",
    "                \"request\": \"I need a compact car with automatic transmission.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class ToHotelBookingAssistant(BaseModel):\n",
    "    \"\"\"Transfer work to a specialized assistant to handle hotel bookings.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants to book a hotel.\"\n",
    "    )\n",
    "    checkin_date: str = Field(description=\"The check-in date for the hotel.\")\n",
    "    checkout_date: str = Field(description=\"The check-out date for the hotel.\")\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the hotel booking.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"location\": \"Zurich\",\n",
    "                \"checkin_date\": \"2023-08-15\",\n",
    "                \"checkout_date\": \"2023-08-20\",\n",
    "                \"request\": \"I prefer a hotel near the city center with a room that has a view.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class ToBookExcursion(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle trip recommendation and other excursion bookings.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants to book a recommended trip.\"\n",
    "    )\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the trip recommendation.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"location\": \"Lucerne\",\n",
    "                \"request\": \"The user is interested in outdoor activities and scenic views.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for Swiss Airlines. \"\n",
    "            \"Your primary role is to search for flight information and company policies to answer customer queries. \"\n",
    "            \"If a customer requests to update or cancel a flight, book a car rental, book a hotel, or get trip recommendations, \"\n",
    "            \"delegate the task to the appropriate specialized assistant by invoking the corresponding tool. You are not able to make these types of changes yourself.\"\n",
    "            \" Only the specialized assistants are given permission to do this for the user.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "            \"Provide detailed information to the customer, and always double-check the database before concluding that information is unavailable. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user flight information:\\n<Flights>\\n{user_info}\\n</Flights>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "primary_assistant_tools = [\n",
    "    TavilySearchResults(max_results=1),\n",
    "    search_flights,\n",
    "    lookup_policy,\n",
    "]\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "    primary_assistant_tools\n",
    "    + [\n",
    "        ToFlightBookingAssistant,\n",
    "        ToBookCarRental,\n",
    "        ToHotelBookingAssistant,\n",
    "        ToBookExcursion,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Assistant**\n",
    "\n",
    "We're about ready to create the graph. In the previous section, we made the design decision to have a shared messages state between all the nodes. This is powerful in that each delegated assistant can see the entire user journey and have a shared context. This, however, means that weaker LLMs can easily get mixed up about there specific scope. To mark the \"handoff\" between the primary assistant and one of the delegated workflows (and complete the tool call from the router), we will add a ToolMessage to the state.\n",
    "\n",
    "**Utility**\n",
    "\n",
    "Create a function to make an \"entry\" node for each workflow, stating \"the current assistant is assistant_name\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically this `create_entry_node` function is just updating the State and explains where we are going. It is like: \n",
    "For a simple task: user's question | primary agent's decision | create_entry_node | new agent's action | response the user\n",
    "\n",
    "For a complex task: user's question | primary agent's decision | create_entry_node | new agent's action | primary agent | create_entry_node | another agent | response the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user.\"\n",
    "                    f\" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},\"\n",
    "                    \" and the booking, update, other other action is not complete until after you have successfully invoked the appropriate tool.\"\n",
    "                    \" If the user changes their mind or needs help for other tasks, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \" Do not mention who you are - just act as the proxy for the assistant.\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": new_dialog_state,\n",
    "        }\n",
    "\n",
    "    return entry_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define Graph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Initialize the builder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`fetch_user_info` Node and `START`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_info(state: State):\n",
    "    return {\"user_info\": fetch_user_flight_information.invoke({})}\n",
    "\n",
    "builder.add_node(\"fetch_user_info\", user_info)\n",
    "builder.add_edge(START, \"fetch_user_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primary assistant Node | leave_skill Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`primary_assistant` Node and primary assistnace's Edge to `primary_assistant_tools`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary assistant\n",
    "builder.add_node(\"primary_assistant\", Assistant(assistant_runnable))\n",
    "builder.add_node(\n",
    "    \"primary_assistant_tools\", create_tool_node_with_fallback(primary_assistant_tools)\n",
    ")\n",
    "builder.add_edge(\"primary_assistant_tools\", \"primary_assistant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`route_primary_assistance` and the conditional edges to 4 sub-agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_primary_assistant(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == ToFlightBookingAssistant.__name__:\n",
    "            return \"enter_update_flight\"\n",
    "        elif tool_calls[0][\"name\"] == ToBookCarRental.__name__:\n",
    "            return \"enter_book_car_rental\"\n",
    "        elif tool_calls[0][\"name\"] == ToHotelBookingAssistant.__name__:\n",
    "            return \"enter_book_hotel\"\n",
    "        elif tool_calls[0][\"name\"] == ToBookExcursion.__name__:\n",
    "            return \"enter_book_excursion\"\n",
    "        return \"primary_assistant_tools\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "\n",
    "# The assistant can route to one of the delegated assistants,\n",
    "# directly use a tool, or directly respond to the user\n",
    "builder.add_conditional_edges(\n",
    "    \"primary_assistant\",\n",
    "    route_primary_assistant,\n",
    "    [\n",
    "        \"enter_update_flight\",\n",
    "        \"enter_book_car_rental\",\n",
    "        \"enter_book_hotel\",\n",
    "        \"enter_book_excursion\",\n",
    "        \"primary_assistant_tools\",\n",
    "        END,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`route_to_workflow` and the Edge from `fetch_user_info` Node to `route_to_workflow`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each delegated workflow can directly respond to the user\n",
    "# When the user responds, we want to return to the currently active workflow\n",
    "def route_to_workflow(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"primary_assistant\",\n",
    "    \"update_flight\",\n",
    "    \"book_car_rental\",\n",
    "    \"book_hotel\",\n",
    "    \"book_excursion\",\n",
    "]:\n",
    "    \"\"\"If we are in a delegated state, route directly to the appropriate assistant.\"\"\"\n",
    "    dialog_state = state.get(\"dialog_state\")\n",
    "    if not dialog_state:\n",
    "        return \"primary_assistant\"\n",
    "    return dialog_state[-1]\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"fetch_user_info\", route_to_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`leave_skill` Node and the Edge from `leave_skill` Node to `primary_assistant` Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_skill\", \"primary_assistant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll start adding our specialized workflows. Each mini-workflow looks very similar to our full graph in Part 3, employing 5 nodes:\n",
    "\n",
    "1. `enter_*`: use the `create_entry_node` utility you defined above to add a ToolMessage signaling that the new specialized assistant is at the helm\n",
    "2. Assistant: the prompt + llm combo that takes in the current state and either uses a tool, asks a question of the user, or ends the workflow (return to the primary assistant)\n",
    "3. `*_safe_tools`: \"read-only\" tools the assistant can use without user confirmation.\n",
    "4. `*_sensitive_tools`: tools with \"write\" access that require user confirmation (and will be assigned an interrupt_before when we compile the graph)\n",
    "5. `leave_skill`: pop the `dialog_state` to signal that the primary assistant is back in control\n",
    "Because of their similarities, we could define a factory function to generate these. Since this is a tutorial, we'll define them each explicitly.\n",
    "\n",
    "First, make the flight booking assistant dedicated to managing the user journey for updating and canceling flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight booking assistant\n",
    "builder.add_node(\n",
    "    \"enter_update_flight\",\n",
    "    create_entry_node(\"Flight Updates & Booking Assistant\", \"update_flight\"),\n",
    ") # technically this \n",
    "builder.add_node(\"update_flight\", Assistant(update_flight_runnable)) # agent's name\n",
    "builder.add_edge(\"enter_update_flight\", \"update_flight\")\n",
    "builder.add_node(\n",
    "    \"update_flight_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(update_flight_sensitive_tools),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"update_flight_safe_tools\",\n",
    "    create_tool_node_with_fallback(update_flight_safe_tools),\n",
    ")\n",
    "\n",
    "\n",
    "def route_update_flight(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state) # Use `tools_condition` in the conditional_edge to route to the ToolNode if the last message has tool calls. Otherwise, route to the end.\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    safe_toolnames = [t.name for t in update_flight_safe_tools]\n",
    "    if all(tc[\"name\"] in safe_toolnames for tc in tool_calls):\n",
    "        return \"update_flight_safe_tools\"\n",
    "    return \"update_flight_sensitive_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"update_flight_sensitive_tools\", \"update_flight\")\n",
    "builder.add_edge(\"update_flight_safe_tools\", \"update_flight\")\n",
    "builder.add_conditional_edges(\n",
    "    \"update_flight\",\n",
    "    route_update_flight,\n",
    "    [\"update_flight_sensitive_tools\", \"update_flight_safe_tools\", \"leave_skill\", END],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the car rental assistant graph to own all car rental needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car rental assistant\n",
    "\n",
    "builder.add_node(\n",
    "    \"enter_book_car_rental\",\n",
    "    create_entry_node(\"Car Rental Assistant\", \"book_car_rental\"),\n",
    ")\n",
    "builder.add_node(\"book_car_rental\", Assistant(book_car_rental_runnable))\n",
    "builder.add_edge(\"enter_book_car_rental\", \"book_car_rental\")\n",
    "builder.add_node(\n",
    "    \"book_car_rental_safe_tools\",\n",
    "    create_tool_node_with_fallback(book_car_rental_safe_tools),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"book_car_rental_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(book_car_rental_sensitive_tools),\n",
    ")\n",
    "\n",
    "\n",
    "def route_book_car_rental(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    safe_toolnames = [t.name for t in book_car_rental_safe_tools]\n",
    "    if all(tc[\"name\"] in safe_toolnames for tc in tool_calls):\n",
    "        return \"book_car_rental_safe_tools\"\n",
    "    return \"book_car_rental_sensitive_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"book_car_rental_sensitive_tools\", \"book_car_rental\")\n",
    "builder.add_edge(\"book_car_rental_safe_tools\", \"book_car_rental\")\n",
    "builder.add_conditional_edges(\n",
    "    \"book_car_rental\",\n",
    "    route_book_car_rental,\n",
    "    [\n",
    "        \"book_car_rental_safe_tools\",\n",
    "        \"book_car_rental_sensitive_tools\",\n",
    "        \"leave_skill\",\n",
    "        END,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the hotel booking workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotel booking assistant\n",
    "builder.add_node(\n",
    "    \"enter_book_hotel\", create_entry_node(\"Hotel Booking Assistant\", \"book_hotel\")\n",
    ")\n",
    "builder.add_node(\"book_hotel\", Assistant(book_hotel_runnable))\n",
    "builder.add_edge(\"enter_book_hotel\", \"book_hotel\")\n",
    "builder.add_node(\n",
    "    \"book_hotel_safe_tools\",\n",
    "    create_tool_node_with_fallback(book_hotel_safe_tools),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"book_hotel_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(book_hotel_sensitive_tools),\n",
    ")\n",
    "\n",
    "\n",
    "def route_book_hotel(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    tool_names = [t.name for t in book_hotel_safe_tools]\n",
    "    if all(tc[\"name\"] in tool_names for tc in tool_calls):\n",
    "        return \"book_hotel_safe_tools\"\n",
    "    return \"book_hotel_sensitive_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"book_hotel_sensitive_tools\", \"book_hotel\")\n",
    "builder.add_edge(\"book_hotel_safe_tools\", \"book_hotel\")\n",
    "builder.add_conditional_edges(\n",
    "    \"book_hotel\",\n",
    "    route_book_hotel,\n",
    "    [\"leave_skill\", \"book_hotel_safe_tools\", \"book_hotel_sensitive_tools\", END],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, define the excursion assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excursion assistant\n",
    "builder.add_node(\n",
    "    \"enter_book_excursion\",\n",
    "    create_entry_node(\"Trip Recommendation Assistant\", \"book_excursion\"),\n",
    ")\n",
    "builder.add_node(\"book_excursion\", Assistant(book_excursion_runnable))\n",
    "builder.add_edge(\"enter_book_excursion\", \"book_excursion\")\n",
    "builder.add_node(\n",
    "    \"book_excursion_safe_tools\",\n",
    "    create_tool_node_with_fallback(book_excursion_safe_tools),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"book_excursion_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(book_excursion_sensitive_tools),\n",
    ")\n",
    "\n",
    "\n",
    "def route_book_excursion(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    tool_names = [t.name for t in book_excursion_safe_tools]\n",
    "    if all(tc[\"name\"] in tool_names for tc in tool_calls):\n",
    "        return \"book_excursion_safe_tools\"\n",
    "    return \"book_excursion_sensitive_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"book_excursion_sensitive_tools\", \"book_excursion\")\n",
    "builder.add_edge(\"book_excursion_safe_tools\", \"book_excursion\")\n",
    "builder.add_conditional_edges(\n",
    "    \"book_excursion\",\n",
    "    route_book_excursion,\n",
    "    [\"book_excursion_safe_tools\", \"book_excursion_sensitive_tools\", \"leave_skill\", END],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create the primary assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # Let the user approve or deny the use of sensitive tools\n",
    "    interrupt_before=[\n",
    "        \"update_flight_sensitive_tools\",\n",
    "        \"book_car_rental_sensitive_tools\",\n",
    "        \"book_hotel_sensitive_tools\",\n",
    "        \"book_excursion_sensitive_tools\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "image_name = \"bot_with_specialized_workflows.png\"\n",
    "\n",
    "if save:\n",
    "    from PIL import Image as PILImage\n",
    "    import io\n",
    "    # Assuming graph.get_graph().draw_mermaid_png() returns PNG binary data\n",
    "    try:\n",
    "        # Generate the PNG image from the graph\n",
    "        png_data = graph.get_graph().draw_mermaid_png()\n",
    "        \n",
    "        # Convert the binary data into an image\n",
    "        img = PILImage.open(io.BytesIO(png_data))\n",
    "        \n",
    "        # Save the image locally with 300 DPI\n",
    "        img.save(image_name, 'PNG', dpi=(1200, 600))\n",
    "        \n",
    "        print(\"Image saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create an example conversation a user might have with the assistant\n",
    "sample_questions = [\n",
    "    # \"Hi there, what time is my flight?\",\n",
    "    \"Am I allowed to update my flight to something sooner? I want to leave later today.\",\n",
    "    # \"Update my flight to sometime next week then\",\n",
    "    # \"The next available option is great\",\n",
    "    # \"what about lodging and transportation?\",\n",
    "    # \"Yeah i think i'd like an affordable hotel for my week-long stay (7 days). And I'll want to rent a car.\",\n",
    "    # \"OK could you place a reservation for your recommended hotel? It sounds nice.\",\n",
    "    # \"yes go ahead and book anything that's moderate expense and has availability.\",\n",
    "    # \"Now for a car, what are my options?\",\n",
    "    # \"Awesome let's just get the cheapest option. Go ahead and book for 7 days\",\n",
    "    # \"Cool so now what recommendations do you have on excursions?\",\n",
    "    # \"Are they available while I'm there?\",\n",
    "    # \"interesting - i like the museums, what options are there? \",\n",
    "    # \"OK great pick one and book it for my second day there.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the databases and set the config for a sample user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utilities import update_dates\n",
    "import uuid\n",
    "\n",
    "# Update with the backup file so we can restart from the original place in each section\n",
    "db = update_dates(CFG.local_file, CFG.backup_file)\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        \"passenger_id\": \"3442 587242\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Bot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_printed = set()\n",
    "# We can reuse the tutorial questions from part 1 to see how it does.\n",
    "for question in sample_questions:\n",
    "    events = graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "    snapshot = graph.get_state(config)\n",
    "    while snapshot.next:\n",
    "        # We have an interrupt! The agent is trying to use a tool, and the user can approve or deny it\n",
    "        # Note: This code is all outside of your graph. Typically, you would stream the output to a UI.\n",
    "        # Then, you would have the frontend trigger a new run via an API call when the user has provided input.\n",
    "        try:\n",
    "            user_input = input(\n",
    "                \"Do you approve of the above actions? Type 'y' to continue;\"\n",
    "                \" otherwise, explain your requested changed.\\n\\n\"\n",
    "            )\n",
    "        except:\n",
    "            user_input = \"y\"\n",
    "        if user_input.strip() == \"y\":\n",
    "            # Just continue\n",
    "            result = graph.invoke(\n",
    "                None,\n",
    "                config,\n",
    "            )\n",
    "        else:\n",
    "            # Satisfy the tool invocation by\n",
    "            # providing instructions on the requested changes / change of mind\n",
    "            result = graph.invoke(\n",
    "                {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            tool_call_id=event[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "                            content=f\"API call denied by user. Reasoning: '{user_input}'. Continue assisting, accounting for the user's input.\",\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                config,\n",
    "            )\n",
    "        snapshot = graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot[0][\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Performance\n",
    "\n",
    "The system works fantastic.\n",
    "\n",
    "## Problems\n",
    "\n",
    "Our Bot is able to handle different tasks using focused workflows.\n",
    "\n",
    "------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airline-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
