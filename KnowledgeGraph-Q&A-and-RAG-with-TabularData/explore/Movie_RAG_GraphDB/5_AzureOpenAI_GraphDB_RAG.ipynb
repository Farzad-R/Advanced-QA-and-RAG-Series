{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "load_dotenv()\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the environment variables from your `.env` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "azure_openai_endpoint = os.environ[\"OPENAI_API_BASE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Azure openAI instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  api_key = azure_openai_api_key,  \n",
    "  api_version = \"2023-07-01-preview\",\n",
    "  azure_endpoint = azure_openai_endpoint\n",
    ")\n",
    "\n",
    "def embed_text(text:str)->List:\n",
    "    \"\"\"\n",
    "    Embeds the given text using the specified model.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to be embedded.\n",
    "\n",
    "    Returns:\n",
    "        List: A list containing the embedding of the text.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "    input = text,\n",
    "    model= \"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Neo4j credentials (These information need to be kept secret)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "NEO4J_DATABASE = 'neo4j'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample question for RAG:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What movies are about love?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the questions embedding:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.004219826776534319,\n",
       " -0.03029683791100979,\n",
       " 0.0007639749674126506,\n",
       " -0.02761838585138321,\n",
       " -0.007965870201587677,\n",
       " 0.0019409307278692722,\n",
       " -0.006576106883585453,\n",
       " -0.021617135033011436,\n",
       " -0.002027790993452072,\n",
       " -0.008066943846642971]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embed_text(question)\n",
    "question_embedding[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Similarity Search using the question's embedding on the vector index of the graph database and get the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'movie.title': 'Heat',\n",
       "  'movie.tagline': 'A Los Angeles crime saga',\n",
       "  'score': 0.8910084962844849},\n",
       " {'movie.title': 'Grumpier Old Men',\n",
       "  'movie.tagline': 'Still Yelling. Still Fighting. Still Ready for Love.',\n",
       "  'score': 0.8878611922264099},\n",
       " {'movie.title': 'Tom and Huck',\n",
       "  'movie.tagline': 'The Original Bad Boys.',\n",
       "  'score': 0.8836773633956909},\n",
       " {'movie.title': 'Sense and Sensibility',\n",
       "  'movie.tagline': 'Lose your heart and come to your senses.',\n",
       "  'score': 0.8762467503547668},\n",
       " {'movie.title': 'Balto',\n",
       "  'movie.tagline': 'Part Dog. Part Wolf. All Hero.',\n",
       "  'score': 0.8755828142166138}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.query(\"\"\"\n",
    "    with $question_embedding as question_embedding      // Use the provided question embedding as 'question_embedding'\n",
    "    CALL db.index.vector.queryNodes(                    // Call the vector index query function\n",
    "        'movie_tagline_embeddings',                     // Name of the vector index to query against\n",
    "        $top_k,                                         // Number of top results to retrieve\n",
    "        question_embedding                              // The question embedding to compare against\n",
    "        ) YIELD node AS movie, score                    // Yield each matched node and its similarity score\n",
    "    RETURN movie.title, movie.tagline, score            // Return the title, tagline, and similarity score of each movie\n",
    "    \"\"\",\n",
    "    params={\n",
    "        \"question_embedding\": question_embedding,       # Pass the question embedding as a parameter\n",
    "        \"top_k\": 5                                      # Specify the number of top results to retrieve\n",
    "    })\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pass the results to an LLM for the final answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some movies that are about love:\n",
      "\n",
      "1. Heat - A Los Angeles crime saga.\n",
      "2. Grumpier Old Men - Still Yelling. Still Fighting. Still Ready for Love.\n",
      "3. Tom and Huck - The Original Bad Boys.\n",
      "4. Sense and Sensibility - Lose your heart and come to your senses.\n",
      "5. Balto - Part Dog. Part Wolf. All Hero.\n",
      "\n",
      "These movies revolve around the theme of love in different ways.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"# Question:\\n{question}\\n\\n# Graph DB search results:\\n{result}\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": str(\n",
    "        \"You will be given the user question along with the search result of that question over a Neo4j graph database. Give the user the proper answer.\"\n",
    "    )},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"gpt_deployment_name\"),\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second example (in one go):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movies about adventure are:\n",
      "1. Toy Story - The adventure takes off!\n",
      "2. Cutthroat Island - The Course Has Been Set. There Is No Turning Back. Prepare Your Weapons. Summon Your Courage. Discover the Adventure of a Lifetime!\n",
      "3. Tom and Huck - The Original Bad Boys.\n",
      "4. Jumanji - Roll the dice and unleash the excitement!\n"
     ]
    }
   ],
   "source": [
    "question = \"What movies are about adventure?\"\n",
    "question_embedding = embed_text(question)\n",
    "result = graph.query(\"\"\"\n",
    "    with $question_embedding as question_embedding\n",
    "    CALL db.index.vector.queryNodes(\n",
    "        'movie_tagline_embeddings', \n",
    "        $top_k, \n",
    "        question_embedding\n",
    "        ) YIELD node AS movie, score\n",
    "    RETURN movie.title, movie.tagline, score\n",
    "    \"\"\",\n",
    "    params={\n",
    "        \"question_embedding\": question_embedding,\n",
    "        \"top_k\": 5\n",
    "    })\n",
    "\n",
    "prompt = f\"# Question:\\n{question}\\n\\n# Graph DB search results:\\n{result}\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": str(\n",
    "        \"You will be given the user question along with the search result of that question over a Neo4j graph database. Give the user the proper answer.\"\n",
    "    )},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"gpt_deployment_name\"),\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playaround",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
